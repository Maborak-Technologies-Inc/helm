# Default values for amazon-watcher-stack
# This is a YAML-formatted file.

nameOverride: "apt"
fullnameOverride: ""

# Global configuration
imagePullSecrets:
  - name: apt-docker-server

global:
  context: amazon-watcher
  domain:
    ui: "ui.asin.local" # UI domain (e.g., "ui.amazon-watcher.local" or "dev-ui.example.com") - Required for ingress
    backend: "api.asin.local" # Backend domain (e.g., "api.amazon-watcher.local" or "dev-api.example.com") - Required for ingress
  # Global HPA override (empty = use individual service settings, true/false = override all)
  hpa: true # Options: "" (use individual), true (enable HPA for all), false (disable HPA for all)
  # Global rollout configuration
  revisionHistoryLimit: 3 # Global default for number of old ReplicaSets to retain
  # Global persistent storage (shared across backend, CLI jobs, and other services)
  # For local clusters with NFS, use "nfs-client"
  # For AWS EKS, use "efs-sc"
  # For GKE/Azure, use your cluster's RWX storage class
  storage:
    enabled: true # Enable global persistent storage
    storageClassName: "nfs-client" # Auto-detect "nfs-client", or use this override, or cluster default if empty
    size: 10Gi # Storage size
    accessModes:
      - ReadWriteMany # Options: ReadWriteOnce, ReadWriteMany (for concurrent access)

# Database Configuration
database:
  enabled: true
  postgres:
    version: "16-alpine"
    db: amazon_watcher
    user: amazon_watcher
    password: amazon_watcher_password
    port: 5432
    dataPath: /var/lib/postgresql/data/pgdata
  storage:
    storageClassName: "" # Keep empty to match existing StatefulSet (avoid immutable field error)
    size: 10Gi
    accessModes:
      - ReadWriteOnce
    # subPath: "db-data"  # Optional: mount a sub-directory of the volume
  # Retention policy for PVCs when StatefulSet is deleted or pods are scaled down
  # Note: Requires Kubernetes 1.27+ or StatefulSetAutoDeletePVC feature gate
  pvcRetentionPolicy:
    whenDeleted: Delete  # Options: Retain (default), Delete
    whenScaled: Retain   # Options: Retain (default), Delete
  resources:
    limits:
      memory: 1Gi
      cpu: 1000m
    requests:
      memory: 512Mi
      cpu: 500m
  healthCheck:
    enabled: true
    intervalSeconds: 5
    timeoutSeconds: 5
    failureThreshold: 5
    initialDelaySeconds: 10
  # Network Policy configuration
  networkPolicy:
    enabled: true # Set to true to enable NetworkPolicy
    # ingress: []  # Custom ingress rules (if not provided, defaults are used)
    # egress: []  # Custom egress rules (if not provided, defaults are used)

# Backend Service Configuration
backend:
  enabled: true
  replicas: 3
  # CLI Rollout configuration (for continuous monitoring/processing)
  cli:
    enabled: true # Set to true to enable CLI Rollout
    replicas: 1 # Number of replicas (used when HPA is disabled)
    storage:
      enabled: true # Enable shared storage now that we have RWX support
    command: "python cli.py monitor run --batch-limit=5 --batch-interval=1 --cooldown-limit=5 --cooldown-duration=5 --country=ALL --short" # Command to run continuously
    waitForBackend: true # Wait for backend service to be ready before starting
    maxWaitSeconds: 300 # Maximum seconds to wait for backend (default: 5 minutes)
    # Autoscaling configuration for CLI Rollout
    autoscaling:
      enabled: true # Set to true to enable HPA for CLI
      minReplicas: 2 # Minimum number of CLI pods (HPA will scale down to this)
      maxReplicas: 5 # Maximum number of CLI pods (HPA will scale up to this)
      targetCPUUtilizationPercentage: 80 # Target CPU utilization percentage
    resources:
      requests:
        memory: 256Mi
        cpu: 100m
      limits:
        memory: 512Mi
        cpu: 500m
    # Rollout configuration for CLI
    rollout:
      revisionHistoryLimit: null # Uses global.revisionHistoryLimit if null
      progressDeadlineSeconds: 1800 # 30 minutes timeout for rollout progress
      # Strategy for sequential pod startup (one pod at a time)
      strategy:
        canary:
          # Sequential pod creation: only 1 new pod at a time
          maxSurge: 1 # Maximum number of pods that can be created above desired replicas
          maxUnavailable: 0 # No pods terminated until new one is ready
          steps:
            # Wait 30 seconds between each pod creation
            - pause:
                duration: 30 # Wait 30 seconds before proceeding to next pod
    # PodDisruptionBudget configuration for CLI
    podDisruptionBudget:
      enabled: false # Set to true to enable PDB for CLI
      minAvailable: 2 # Minimum number of pods that must be available during disruptions
      # maxUnavailable: 1  # Alternative: Maximum number of pods that can be unavailable
  # CronJob configuration (for periodic tasks)
  cronjob:
    enabled: true # Set to true to enable CronJob
    schedule: "*/10 * * * *" # Run every 10 minutes (cron format)
    command: "python cli.py monitor cookie --orphans" # Command to run periodically
    waitForBackend: true # Wait for backend service to be ready before running
    maxWaitSeconds: 300 # Maximum seconds to wait for backend (default: 5 minutes)
    concurrencyPolicy: Forbid # Prevent concurrent job executions (Forbid, Allow, Replace)
    successfulJobsHistoryLimit: 3 # Number of successful jobs to keep
    failedJobsHistoryLimit: 1 # Number of failed jobs to keep
    suspend: false # Set to true to suspend the CronJob
    backoffLimit: 3 # Number of retries before marking job as failed
    activeDeadlineSeconds: 600 # Maximum seconds a job can run (default: 10 minutes)
    resources:
      limits:
        memory: 512Mi
        cpu: 500m
      requests:
        memory: 256Mi
        cpu: 100m
    # Note: CronJob does not support autoscaling (HPA)
    # CronJob creates Jobs on schedule - each Job runs pods to completion
    # For autoscaling, use Rollout/Deployment instead
    # Pod Disruption Budget configuration
    podDisruptionBudget:
      enabled: true # Set to true to enable PDB
      # minAvailable: 2  # Minimum number of pods that must be available (mutually exclusive with maxUnavailable)
      maxUnavailable: 1 # Maximum number of pods that can be unavailable
  image:
    repository: maborak/platform
    tag: "apt-backend-0.2"
    pullPolicy: Always
  resources:
    limits:
      memory: 1Gi
      cpu: 1000m
    requests:
      memory: 256Mi
      cpu: 200m
  service:
    type: ClusterIP # Options: ClusterIP, NodePort, LoadBalancer
    # nodePort: 30090  # Only used if type is NodePort
  healthCheck:
    enabled: true
    path: /health
    port: 9000
    # Readiness: Fast checks. If it fails, cut traffic immediately.
    readinessProbe:
      initialDelaySeconds: 15
      periodSeconds: 5
      timeoutSeconds: 5
      failureThreshold: 2
    # Liveness: Patient checks. Only restart if truly stuck.
    livenessProbe:
      initialDelaySeconds: 60
      periodSeconds: 20
      timeoutSeconds: 10
      failureThreshold: 5
    # Legacy flat structure support (optional, can be removed if strict structure is preferred)
    initialDelaySeconds: 40
    periodSeconds: 30
    timeoutSeconds: 10
    failureThreshold: 3
  # Backend environment variables (APT_BACKEND_* prefix)
  # All env vars with full names including prefix - no transformation needed
  env:
    APT_BACKEND_DATABASE_URL: "postgresql://postgres:Dgo7cQ41WDTnd89G46TgfVtr@10.10.10.189:6432/postgres" # External database URL
    APT_BACKEND_DB_USE_REPLICA_ENGINE: "true"
    APT_BACKEND_DB_READ_URL: "postgresql://postgres:Dgo7cQ41WDTnd89G46TgfVtr@10.10.10.189:6433/postgres" # Read replica database URL (optional, for read-only queries)
    APT_BACKEND_DB_WRITE_URL: "postgresql://postgres:Dgo7cQ41WDTnd89G46TgfVtr@10.10.10.189:6432/postgres" # Write database URL (optional, for write operations)
    APT_BACKEND_DB_ECHO: "false"
    APT_BACKEND_DB_ECHO_POOL: "false"
    APT_BACKEND_DB_POOL_SIZE: "20"
    APT_BACKEND_DB_MAX_OVERFLOW: "30"
    APT_BACKEND_DB_POOL_TIMEOUT: "30"
    APT_BACKEND_DB_POOL_RECYCLE: "3600"

    APT_BACKEND_DB_READ_POOL_SIZE: "10" # Read replica connection pool size
    APT_BACKEND_DB_WRITE_POOL_SIZE: "20" # Write database connection pool size
    APT_BACKEND_UVI_HOST: "0.0.0.0"
    APT_BACKEND_UVI_PORT: "9000"
    APT_BACKEND_RELOAD: "false"
    APT_BACKEND_LOG_LEVEL: "info"
    APT_BACKEND_CLI_LOG_LEVEL: "info"
    APT_BACKEND_DEBUG_MODE: "false"
    APT_BACKEND_UVI_ACCESS_LOG: "true"
    APT_BACKEND_UVI_WORKERS: "5"
    APT_BACKEND_UVI_LIMIT_CONCURRENCY: "100"
    APT_BACKEND_UVI_LIMIT_MAX_REQUESTS: "1000"
    APT_BACKEND_UVI_TIMEOUT_KEEP_ALIVE: "30"
    APT_BACKEND_UVI_TIMEOUT_GRACEFUL_SHUTDOWN: "30"
    APT_BACKEND_JWT_ALGORITHM: "HS256"
    APT_BACKEND_JWT_ACCESS_TOKEN_EXPIRY: "3600"
    APT_BACKEND_JWT_REFRESH_TOKEN_EXPIRY: "2592000"
    # CAPTCHA Configuration
    APT_BACKEND_CAPTCHA_TYPE: "turnstile" # Options: "none" (disabled), "recaptcha_v3" (Google), "turnstile" (Cloudflare)
    APT_BACKEND_RECAPTCHA_V3_SECRET_KEY: "6Lejc1csAAAAAI-_ifGaGOLIK8jyk3Mv78-i3wtp" # Google reCAPTCHA v3 secret key
    APT_BACKEND_TURNSTILE_SECRET_KEY: "0x4AAAAAACSywaSu-nfefLxLT2pQJxV5vf0" # Cloudflare Turnstile secret key
    APT_BACKEND_RECAPTCHA_V3_THRESHOLD: "0.5" # reCAPTCHA v3 score threshold (0.0 to 1.0)
    # Domain Configuration
    DOMAIN_UI: "" # UI domain for email links (verification, password reset, etc.) - Auto-generated from global.domain.ui if empty
    APT_BACKEND_CORS_ORIGINS: "*"
    APT_BACKEND_CORS_ALLOW_CREDENTIALS: "true"
    APT_BACKEND_CORS_ALLOW_METHODS: "*"
    APT_BACKEND_CORS_ALLOW_HEADERS: "*"
    APT_BACKEND_CORS_EXPOSE_HEADERS: ""
    APT_BACKEND_CORS_MAX_AGE: "600"
    APT_BACKEND_RATE_LIMIT_ENABLED: "true"
    APT_BACKEND_RATE_LIMIT_REQUESTS: "20"
    APT_BACKEND_RATE_LIMIT_WINDOW: "60"
    APT_BACKEND_RATE_LIMIT_BYPASS_KEY: ""
    APT_BACKEND_RATE_LIMIT_EXCLUDED_PATHS: "/docs,/redoc,/openapi.json,/favicon.ico,/health"
    APT_BACKEND_RATE_LIMIT_BYPASS_PATHS: ""
    # Rate limiting for authentication endpoints
    APT_BACKEND_RATE_LIMIT_AUTH_LOGIN_MAX_REQUESTS: "200"
    APT_BACKEND_RATE_LIMIT_AUTH_LOGIN_WINDOW: "60"
    APT_BACKEND_RATE_LIMIT_AUTH_REGISTER_MAX_REQUESTS: "200"
    APT_BACKEND_RATE_LIMIT_AUTH_REGISTER_WINDOW: "60"
    APT_BACKEND_RATE_LIMIT_AUTH_VERIFY_MAX_REQUESTS: "500"
    APT_BACKEND_RATE_LIMIT_AUTH_VERIFY_WINDOW: "3600"
    APT_BACKEND_RATE_LIMIT_AUTH_PASSWORD_RESET_MAX_REQUESTS: "500"
    APT_BACKEND_RATE_LIMIT_AUTH_PASSWORD_RESET_WINDOW: "300"
    APT_BACKEND_RATE_LIMIT_AUTH_REFRESH_MAX_REQUESTS: "400"
    APT_BACKEND_RATE_LIMIT_AUTH_REFRESH_WINDOW: "60"
    APT_BACKEND_MONITOR_ENABLED: "true"
    APT_BACKEND_MONITOR_INTERVAL: "3600"
    APT_BACKEND_MONITOR_BATCH_SIZE: "5"
    APT_BACKEND_PRICE_HISTORY_PERIODIC_SECONDS: "3600"
    APT_BACKEND_DEFAULT_COUNTRY: "BO"
    APT_BACKEND_HTTP_ENGINE: "requests"
    APT_BACKEND_HTTP_TIMEOUT: "10.0"
    APT_BACKEND_HTTP_RETRIES: "1"
    APT_BACKEND_HTTP_MAX_CONNECTIONS: "10"
    APT_BACKEND_USER_AGENT: "Mozilla/5.0 (X11; Linux aarch64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/128.0.6613.18 Safari/537.36"
    # API limits and pagination
    APT_BACKEND_API_PAGE_SIZE_DEFAULT: "10"
    APT_BACKEND_API_PAGE_SIZE_MAX: "100"
    APT_BACKEND_API_PRICE_HISTORY_LIMIT_DEFAULT: "10"
    APT_BACKEND_API_PRICE_HISTORY_LIMIT_MAX: "200"
    APT_BACKEND_API_PRICE_HISTORY_LIMIT_FULL: "1000"
    APT_BACKEND_API_QUEUE_LIMIT_DEFAULT: "1"
    APT_BACKEND_API_QUEUE_LIMIT_MAX: "50"
    APT_BACKEND_API_BENCH_LIMIT_DEFAULT: "10"
    APT_BACKEND_API_BENCH_LIMIT_MAX: "100"
    # Database table names
    APT_BACKEND_TABLE_CURRENCIES: "currencies"
    APT_BACKEND_TABLE_PRODUCT_STATES: "product_states"
    APT_BACKEND_TABLE_PROCESS_STATES: "process_states"
    APT_BACKEND_TABLE_PRODUCT_CHECKS: "product_checks"
    APT_BACKEND_TABLE_PRICE_HISTORY: "price_history"
    APT_BACKEND_TABLE_SCREENSHOTS: "screenshots"
    APT_BACKEND_TABLE_COUNTRIES: "countries"
    APT_BACKEND_TABLE_WORKERS: "workers"
    APT_BACKEND_TABLE_BENCH: "bench"
    APT_BACKEND_TABLE_USERS: "users"
    APT_BACKEND_TABLE_USER_SESSIONS: "user_sessions"
    APT_BACKEND_TABLE_USER_TOKENS: "user_tokens"
    APT_BACKEND_TABLE_USER_PERMISSIONS: "user_permissions"
    APT_BACKEND_TABLE_PRODUCT_PROCESSING_LOGS: "product_processing_logs"
    APT_BACKEND_SCREENSHOT_ENABLED: "true"
    APT_BACKEND_SCREENSHOT_ON_PRICE_CHANGE_ONLY: "false"
    APT_BACKEND_SCREENSHOT_ON_CHANGES: "false"
    APT_BACKEND_SCREENSHOT_ALWAYS: "true"
    APT_BACKEND_SCREENSHOT_MAX_RETRIES: "3"
    APT_BACKEND_SCREENSHOT_STORAGE_PATH: "/var/screenshots" # Mounted from global.storage (shared with CLI Job)
    APT_BACKEND_SCREENSHOT_SERVICE_URL: "http://192.168.0.40:3000/amazon" # Auto-generated from screenshot service if empty
    APT_BACKEND_SCREENSHOT_SERVICE_WIDTH: "1200"
    APT_BACKEND_SCREENSHOT_SERVICE_HEIGHT: "960"
    APT_BACKEND_SCREENSHOT_SERVICE_FULL_PAGE: "false"
    APT_BACKEND_SCREENSHOT_SERVICE_JAVASCRIPT_ENABLED: "false"
    APT_BACKEND_SCREENSHOT_SERVICE_STOP_ON_CAPTCHA: "false"
    APT_BACKEND_SCREENSHOT_SERVICE_BROWSER_TYPE: "chromium"
    APT_BACKEND_BENCH_KEY: "sdhdfkjhsdhfkshdfjhsd"
    APT_BACKEND_TEST_MODE: "false"
    # Cookie lifetime threshold (for --orphans flag)
    APT_BACKEND_COOKIE_LIFETIME: "3600"
    # Hook Handlers Configuration
    APT_BACKEND_HOOKS_USE_DB_CONFIG: "false" # Use database config for hook handlers
    APT_BACKEND_HOOK_LOG_ENABLED: "true" # Enable log handler
    # Email Handler Configuration
    APT_BACKEND_HOOK_EMAIL_ENABLED: "true" # Enable email handler
    APT_BACKEND_HOOK_EMAIL_SENDER: "wilmer@maborak.com" # Email sender address
    APT_BACKEND_HOOK_EMAIL_SENDER_NAME: "Amazon Watcher" # Email sender name
    APT_BACKEND_HOOK_EMAIL_RECEIVER: "maborak@gmail.com" # Default email receiver
    APT_BACKEND_HOOK_EMAIL_USERNAME: "sender" # SMTP username
    APT_BACKEND_HOOK_EMAIL_PASSWORD: "nulled-by-wilmer-taiquuj0ieng6Sa9Veejoh" # SMTP password
    APT_BACKEND_HOOK_EMAIL_SMTP_HOST: "142.44.188.182" # SMTP host
    APT_BACKEND_HOOK_EMAIL_SMTP_PORT: "2525" # SMTP port
    APT_BACKEND_HOOK_EMAIL_SMTP_SECURITY: "plain" # SMTP security: "ssl", "starttls", or "plain"
    APT_BACKEND_HOOK_EMAIL_SMTP_VERIFY_SSL: "false" # Verify SSL certificate
    APT_BACKEND_HOOK_EMAIL_CONTENT_ENCODING: "quoted-printable" # Content encoding: "quoted-printable", "base64", or "7bit"
    APT_BACKEND_HOOK_EMAIL_TEMPLATE_SET: "infra-aws" # Email template set name (e.g., "default", "minimal", "corporate")
    APT_BACKEND_HOOK_EMAIL_TEMPLATES_DIR: "" # Custom templates directory path (empty for default)
    APT_BACKEND_HOOK_EMAIL_NOTIFY_NEW: "true" # Notify on new products
    APT_BACKEND_HOOK_EMAIL_NOTIFY_CHANGED: "true" # Notify on changed products
    APT_BACKEND_HOOK_EMAIL_NOTIFY_UPDATED: "false" # Notify on updated products
    APT_BACKEND_HOOK_EMAIL_NOTIFY_NOT_CHANGED: "false" # Notify on unchanged products
    APT_BACKEND_HOOK_EMAIL_NOTIFY_SAVED: "false" # Notify on saved products
    APT_BACKEND_HOOK_EMAIL_NOTIFY_USERS: "true"
    APT_BACKEND_HOOK_NOTIFY_USERS_PRICE_CHECKED: "false"
    APT_BACKEND_HOOK_NOTIFY_USERS_PRICE_NOT_CHANGED: "false"
    APT_BACKEND_HOOK_EMAIL_NOTIFY_VERIFICATION: "true" # Send verification emails
    APT_BACKEND_HOOK_EMAIL_VERIFICATION_PATH: "/account/verify" # Verification link path (appended to DOMAIN_UI)
    APT_BACKEND_HOOK_EMAIL_RECIPIENT_VERIFICATION_PATH: "/account/verify-recipient"
    APT_BACKEND_HOOK_EMAIL_NOTIFY_PASSWORD_RESET: "true" # Send password reset emails
    APT_BACKEND_HOOK_EMAIL_PASSWORD_RESET_PATH: "/account/reset-password" # Password reset link path (appended to DOMAIN_UI)
    APT_BACKEND_DATA_SOURCE: "scraping"
  # Screenshot storage volume (deprecated - use global.storage instead)
  # This section is kept for backward compatibility but is ignored if global.storage.enabled is true
  screenshotStorage:
    enabled: false # Deprecated: use global.storage instead
  # Pod Disruption Budget configuration
  podDisruptionBudget:
    enabled: false # Set to true to enable PDB
    # minAvailable: 1  # Minimum number of pods that must be available (mutually exclusive with maxUnavailable)
    maxUnavailable: 1 # Maximum number of pods that can be unavailable
  # Network Policy configuration
  networkPolicy:
    enabled: false # Set to true to enable NetworkPolicy
    # ingress: []  # Custom ingress rules (if not provided, defaults are used)
    # egress: []  # Custom egress rules (if not provided, defaults are used)
  # Argo Rollout configuration
  rollout:
    revisionHistoryLimit: null # Uses global.revisionHistoryLimit if null
    progressDeadlineSeconds: 1800 # 30 minutes timeout for rollout progress
    # Deployment strategy (optional - defaults to simple canary with no steps)
    # If not specified, uses canary strategy with empty steps (rolling update behavior)
    # To enable progressive canary deployment (Upwork-style), uncomment and configure:
    strategy:
      canary:
        # Minimum pods per replica set (ensures canary has enough pods)
        minPodsPerReplicaSet: 0  # Minimum pods to remain during rollout
        # Canary deployment steps (progressive rollout)
        # Note: setWeight requires trafficRouting (Istio/NGINX) to actually split traffic
        # Without trafficRouting, this is metadata-only for tracking progress
        steps:
          # Step 1: Set initial traffic weight (1%)
          - setWeight: 1
          # Step 2: Verify canary pod is healthy before proceeding
          # Checks the health endpoint 3 times with 30s intervals
          # Fails if any check returns non-200 status code
          - analysis:
              templates:
                - templateName: backend-health-check
          # Step 3: Pause for manual verification (duration: 0 = manual pause)
          - pause:
              duration: 0 # Manual pause - requires promotion via ArgoCD UI or CLI
          # Step 4: Set traffic weight to 50%
          - setWeight: 50
          # Step 5: Pause for automated verification (10 minutes)
          - pause:
              duration: 60 # 1 minutes (60 seconds)
          # Step 6: Complete rollout (100% traffic)
          - setWeight: 100
        # Optional: Traffic routing (requires Istio/Linkerd service mesh)
        # trafficRouting:
        #   istio:
        #     virtualService:
        #       name: backend
        #     destinationRule:
        #       name: backend
        #       stableSubsetName: stable
        #       canarySubsetName: canary
    # Alternative: Blue-Green deployment
    # strategy:
    #   blueGreen:
    #     activeService: backend
    #     previewService: backend-preview
    #     autoPromotionEnabled: true
  # Horizontal Pod Autoscaler configuration
  autoscaling:
    enabled: true # Set to true to enable HPA
    minReplicas: 1
    maxReplicas: 3
    targetCPUUtilizationPercentage: 80
    # targetMemoryUtilizationPercentage: 80  # Optional: enable memory-based scaling
    # behavior:  # Optional: customize scaling behavior
    #   scaleDown:
    #     stabilizationWindowSeconds: 300
    #     policies:
    #     - type: Percent
    #       value: 50
    #       periodSeconds: 60
    #   scaleUp:
    #     stabilizationWindowSeconds: 0
    #     policies:
    #     - type: Percent
    #       value: 100
    #       periodSeconds: 15

# Maborak Deployment Configuration
# A utility deployment for running migrations and other administrative commands
# Uses the same image and configuration as backend, but runs sleep infinity
maborak:
  enabled: true # Set to true to enable Maborak deployment
  replicas: 1 # Number of replicas (typically 1 for utility pod)
  revisionHistoryLimit: null # Uses global.revisionHistoryLimit if null
  resources:
    limits:
      memory: 1Gi
      cpu: 1000m
    requests:
      memory: 512Mi
      cpu: 500m
  # Network Policy configuration
  networkPolicy:
    enabled: true # Set to true to enable NetworkPolicy (required for database access if network policies are enforced)
    # egress: []  # Custom egress rules (if not provided, defaults allow database and screenshot access)
    allowed: ["192.168.0.0/24"] # List of CIDR ranges to allow egress to (e.g., ["1.1.1.1/32", "8.8.8.8/32"])

# UI Service Configuration
ui:
  enabled: true
  replicas: 1
  image:
    repository: maborak/platform
    tag: "apt-ui-0.2"
    pullPolicy: Always
  resources:
    limits:
      memory: 2Gi
      cpu: 500m
    requests:
      memory: 512Mi
      cpu: 100m
  service:
    type: ClusterIP # Options: ClusterIP, NodePort, LoadBalancer
    # nodePort: 30080  # Only used if type is NodePort
  healthCheck:
    enabled: true
    path: /
    port: 80
    initialDelaySeconds: 10
    periodSeconds: 30
    timeoutSeconds: 10
    failureThreshold: 3
  # UI environment variables (VITE_* prefix)
  # All env vars with full names including prefix - no transformation needed
  env:
    VITE_API_BASE_URL: "" # Auto-generated from backend domain if empty (uses //api.amazon-watcher.local)
    VITE_API_TIMEOUT: "30"
    VITE_API_CACHE_TTL: "10000"
    VITE_CONNECTIVITY_CHECK_INTERVAL: "60"
    VITE_APP_NAME: "Amazon Watcher"
    VITE_APP_VERSION: "1.0.0"
    VITE_LOADER_TYPE: "shimmer" # Options: simple, progress_bar, skeleton, shimmer
    VITE_BUILD_DATE: ""
    VITE_DEFAULT_COUNTRY: "ALL"
    VITE_DEFAULT_COUNTRY_DATA: "US"
    VITE_PRICE_HISTORY_LIMIT: "50"
    VITE_PRICE_HISTORY_PAGE_SIZE: "10"
    VITE_DEBUG_MODE: "true"
    VITE_LOG_LEVEL: "info"
    # CAPTCHA Configuration
    VITE_CAPTCHA_PROVIDER: "turnstile" # Options: "none" (disabled), "recaptcha_v3" (Google), "turnstile" (Cloudflare)
    VITE_RECAPTCHA_SITE_KEY: "6Lejc1csAAAAAMcSkjVoAD4xGm1Nm6aIwhy1AUrL" # Google reCAPTCHA v3 site key (public key)
    VITE_TURNSTILE_SITE_KEY: "0x4AAAAAACSywe2vgnS_c_an" # Cloudflare Turnstile site key (public key)
  # Pod Disruption Budget configuration
  podDisruptionBudget:
    enabled: false # Set to true to enable PDB
    # minAvailable: 1  # Minimum number of pods that must be available (mutually exclusive with maxUnavailable)
    maxUnavailable: 1 # Maximum number of pods that can be unavailable
  # Network Policy configuration
  networkPolicy:
    enabled: false # Set to true to enable NetworkPolicy
    # ingress: []  # Custom ingress rules (if not provided, defaults are used)
    # egress: []  # Custom egress rules (if not provided, defaults are used)
  # Argo Rollout configuration
  rollout:
    revisionHistoryLimit: null # Uses global.revisionHistoryLimit if null
    progressDeadlineSeconds: 1800 # 30 minutes timeout for rollout progress
    # Deployment strategy (optional - defaults to simple canary with no steps)
    # If not specified, uses canary strategy with empty steps (rolling update behavior)
    # To enable progressive canary deployment (Upwork-style), uncomment and configure:
    strategy:
      canary:
        # Minimum pods per replica set (ensures canary has enough pods)
        minPodsPerReplicaSet: 0  # Minimum pods to remain during rollout
        # Canary deployment steps (progressive rollout)
        # Note: setWeight requires trafficRouting (Istio/NGINX) to actually split traffic
        # Without trafficRouting, this is metadata-only for tracking progress
        steps:
          # Step 1: Set initial traffic weight (1%)
          - setWeight: 1
          # Step 2: Pause for manual verification (duration: 0 = manual pause)
          - pause:
              duration: 0 # Manual pause - requires promotion via ArgoCD UI or CLI
          # Step 3: Set traffic weight to 50%
          - setWeight: 50
          # Step 4: Pause for automated verification (2 minutes)
          - pause:
              duration: 120 # 2 minutes (120 seconds)
          # Step 5: Complete rollout (100% traffic)
          - setWeight: 100
        # Optional: Analysis templates for automated verification
        # analysis:
        #   templates:
        #   - templateName: ui-analysis
        # Optional: Traffic routing (requires Istio/Linkerd service mesh)
        # trafficRouting:
        #   istio:
        #     virtualService:
        #       name: ui
        #     destinationRule:
        #       name: ui
        #       stableSubsetName: stable
        #       canarySubsetName: canary
    # Alternative: Blue-Green deployment
    # strategy:
    #   blueGreen:
    #     activeService: ui
    #     previewService: ui-preview
    #     autoPromotionEnabled: true
  # Horizontal Pod Autoscaler configuration
  autoscaling:
    enabled: true # Set to true to enable HPA
    minReplicas: 1
    maxReplicas: 10
    targetCPUUtilizationPercentage: 80
    # targetMemoryUtilizationPercentage: 80  # Optional: enable memory-based scaling
    # behavior:  # Optional: customize scaling behavior
    #   scaleDown:
    #     stabilizationWindowSeconds: 300
    #     policies:
    #     - type: Percent
    #       value: 50
    #       periodSeconds: 60
    #   scaleUp:
    #     stabilizationWindowSeconds: 0
    #     policies:
    #     - type: Percent
    #       value: 100
    #       periodSeconds: 15

# Screenshot Service Configuration
screenshot:
  enabled: true
  replicas: 1
  image:
    repository: maborak/platform
    tag: "apt-browser-0.2.1"
    pullPolicy: Always
  resources:
    limits:
      memory: 2Gi
      cpu: 800m
    requests:
      memory: 1Gi
      cpu: 500m
  service:
    type: ClusterIP # Options: ClusterIP, NodePort, LoadBalancer
    # nodePort: 30300  # Only used if type is NodePort
  healthCheck:
    enabled: true
    path: /health
    port: 3000
    initialDelaySeconds: 10
    periodSeconds: 30
    timeoutSeconds: 10
    failureThreshold: 3
  # Argo Rollout configuration
  rollout:
    revisionHistoryLimit: null # Uses global.revisionHistoryLimit if null
    progressDeadlineSeconds: 1800 # 30 minutes timeout for rollout progress
    # Deployment strategy (optional - defaults to simple canary with no steps)
    # If not specified, uses canary strategy with empty steps (rolling update behavior)
    # To enable progressive canary deployment (Upwork-style), uncomment and configure:
    strategy:
      canary:
        # Minimum pods per replica set (ensures canary has enough pods)
        minPodsPerReplicaSet: 0  # Minimum pods to remain during rollout
        # Canary deployment steps (progressive rollout)
        # Note: setWeight requires trafficRouting (Istio/NGINX) to actually split traffic
        # Without trafficRouting, this is metadata-only for tracking progress
        steps:
          # Step 1: Set initial traffic weight (1%)
          - setWeight: 1
          # Step 2: Pause for manual verification (duration: 0 = manual pause)
          - pause:
              duration: 0 # Manual pause - requires promotion
          # Step 3: Set traffic weight to 50%
          - setWeight: 50
          # Step 4: Pause for automated verification (2 minutes)
          - pause:
              duration: 120 # 2 minutes
          # Step 5: Complete rollout (100% traffic)
          - setWeight: 100
        # Optional: Analysis templates for automated verification
        # analysis:
        #   templates:
        #   - templateName: screenshot-analysis
        # Optional: Traffic routing (requires Istio/Linkerd service mesh)
        # trafficRouting:
        #   istio:
        #     virtualService:
        #       name: screenshot
        #     destinationRule:
        #       name: screenshot
        #       stableSubsetName: stable
        #       canarySubsetName: canary
    # Alternative: Blue-Green deployment
    # strategy:
    #   blueGreen:
    #     activeService: screenshot
    #     previewService: screenshot-preview
    #     autoPromotionEnabled: true
  # Horizontal Pod Autoscaler configuration
  autoscaling:
    enabled: true
    minReplicas: 1
    maxReplicas: 3
    targetCPUUtilizationPercentage: 90
    targetMemoryUtilizationPercentage: null # Set to enable memory-based scaling
    # Optional: Custom scaling behavior
    # behavior:
    #   scaleDown:
    #     stabilizationWindowSeconds: 300
    #     policies:
    #     - type: Percent
    #       value: 50
    #       periodSeconds: 60
    #   scaleUp:
    #     stabilizationWindowSeconds: 0
    #     policies:
    #     - type: Percent
    #       value: 100
    #       periodSeconds: 60
    #     - type: Pods
    #       value: 2
    #       periodSeconds: 60
    #     selectPolicy: Max
  # Browser environment variables (APT_BROWSER_* prefix)
  # All env vars with full names including prefix - no transformation needed
  env:
    APT_BROWSER_HOST: "0.0.0.0"
    APT_BROWSER_PORT: "3000"
    APT_BROWSER_RELOAD: "false"
    APT_BROWSER_WORKERS: "1"
    APT_BROWSER_LOG_LEVEL: "INFO"
    APT_BROWSER_ACCESS_LOG: "true"
    APT_BROWSER_LIMIT_CONCURRENCY: "100"
    APT_BROWSER_LIMIT_MAX_REQUESTS: "1000"
    APT_BROWSER_TIMEOUT_KEEP_ALIVE: "5"
    APT_BROWSER_TIMEOUT_GRACEFUL_SHUTDOWN: "30"
    APT_BROWSER_BROWSER_HEADLESS: "true"
    APT_BROWSER_BROWSER_TIMEOUT: "30000"
    APT_BROWSER_BROWSER_IDLE_TIMEOUT: "300"
    APT_BROWSER_MAX_CONCURRENT: "100"
    APT_BROWSER_REQUEST_TIMEOUT: "120"
    APT_BROWSER_DEFAULT_WIDTH: "1920"
    APT_BROWSER_DEFAULT_HEIGHT: "1080"
    APT_BROWSER_DEFAULT_FULL_PAGE: "false"
    APT_BROWSER_DEFAULT_WAIT_UNTIL: "networkidle"
    APT_BROWSER_DEFAULT_MAX_RETRIES: "3"
    APT_BROWSER_DEFAULT_STOP_ON_CAPTCHA: "false"
    APT_BROWSER_DEFAULT_JAVASCRIPT_ENABLED: "true"
    APT_BROWSER_DEFAULT_BROWSER_TYPE: "chromium"
    APT_BROWSER_CAPTCHA_SCROLL_STEP: "500"
    APT_BROWSER_CAPTCHA_RETRY_DELAY_MIN: "2.0"
    APT_BROWSER_CAPTCHA_RETRY_DELAY_MAX: "4.0"
    APT_BROWSER_NAVIGATION_MAX_RETRIES: "3"
    APT_BROWSER_USER_AGENT: "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36"
  # Affinity configuration
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: app.kubernetes.io/component
            operator: In
            values:
            - screenshot
        topologyKey: "kubernetes.io/hostname"
  # Pod Disruption Budget configuration
  podDisruptionBudget:
    enabled: false # Set to true to enable PDB
    # minAvailable: 1  # Minimum number of pods that must be available (mutually exclusive with maxUnavailable)
    maxUnavailable: 1 # Maximum number of pods that can be unavailable
  # Network Policy configuration
  networkPolicy:
    enabled: false # Set to true to enable NetworkPolicy
    # ingress: []  # Custom ingress rules (if not provided, defaults are used)
    # egress: []  # Custom egress rules (if not provided, defaults are used)

# Istio Service Mesh Configuration
# Required for Argo Rollouts traffic splitting with canary deployments
istio:
  enabled: false # Set to true if Istio is installed in your cluster
  virtualService:
    enabled: false # Set to true to create VirtualService for traffic routing
    # Custom routes (if not provided, default routes for Rollout canary are used)
    # routes: []
  destinationRule:
    enabled: false # Set to true to create DestinationRule for canary subsets
    # Custom traffic policy (optional)
    # trafficPolicy: {}
  telemetry:
    enabled: false # Set to true to create Telemetry resources for observability
    # Custom metrics configuration (optional)
    # metrics: []
    # Custom access logging (optional)
    # accessLogging: []
    # Custom tracing (optional)
    # tracing: []

# Kubernetes Ingress Configuration
# Works with any ingress controller (NGINX, Traefik, etc.)
# Note: Ingress resources are only created if both enabled=true AND className is set
ingress:
  enabled: true
  className: "nginx" # Set to your ingress controller class (e.g., "nginx", "traefik"). If empty, Ingress resources will not be created.

  # TLS/SSL Configuration
  tls:
    enabled: false
    # If enabled, you need to provide TLS certificates
    # You can use cert-manager for automatic certificate management
    # or manually create TLS secrets

# Secrets (sensitive values)
secrets:
  # Database password (if not using database.postgres.password)
  databasePassword: ""
  # JWT secret for backend
  jwtSecret: ""

# Service Account
serviceAccount:
  create: true
  annotations: {}
  name: ""

# Pod Security Context
podSecurityContext:
  fsGroup: 2000
  runAsNonRoot: true
  runAsUser: 1000

# Security Context
securityContext:
  capabilities:
    drop:
      - ALL
  readOnlyRootFilesystem: false
  allowPrivilegeEscalation: false

# Node Selector
nodeSelector: {}

# Tolerations
tolerations: []

# Affinity
affinity: {}

# Annotations
podAnnotations: {}

# Labels
podLabels: {}

# ArgoCD Configuration
argocd:
  # ArgoCD annotations for sync control and metadata
  annotations:
    # Application metadata (similar to Upwork pattern)
    app.maborak.com/contact: "wilmer@maborak.com" # e.g., "team@maborak.com"
    app.maborak.com/created-by: "argo-cd" # Indicates ArgoCD created this resource
    app.maborak.com/department: "Platform" # e.g., "platform", "engineering"
    app.maborak.com/project: "amazon-watcher-stack" # e.g., "amazon-watcher"

    # Argo Rollouts notifications (Slack, etc.)
    # notifications.argoproj.io/subscribe.on-rollout-aborted.slack: "channel-name"
    # notifications.argoproj.io/subscribe.on-rollout-completed.slack: "channel-name"
    # notifications.argoproj.io/subscribe.on-rollout-step-completed.slack: "channel-name"
    # notifications.argoproj.io/subscribe.on-rollout-updated.slack: "channel-name"

    # Sync control annotations
    # argocd.argoproj.io/sync-wave: "0"  # Lower numbers sync first
    # argocd.argoproj.io/sync-options: "Prune=false"  # Comma-separated options
    # argocd.argoproj.io/hook: "PreSync"  # Hook type: PreSync, PostSync, Sync, Skip
    # argocd.argoproj.io/hook-weight: "0"  # Hook execution order
    # argocd.argoproj.io/refresh: "hard"  # Refresh mode: normal, hard
    # argocd.argoproj.io/compare-options: "IgnoreExtraneous"  # Compare options

  # Application labels (similar to Upwork pattern)
  labels:
    # Standard Kubernetes labels (already included in common labels)
    # app.kubernetes.io/name, app.kubernetes.io/instance, app.kubernetes.io/component
    # app.kubernetes.io/managed-by, app.kubernetes.io/version, app.kubernetes.io/part-of

    # Organization-specific labels
    app.maborak.com/bounded-context: "amazon-watcher-stack" # Domain/bounded context
    app.maborak.com/chart-name: "amazon-watcher-stack" # Helm chart name
    app.maborak.com/cluster-name: "amazon-watcher-stack" # Kubernetes cluster name
    app.maborak.com/environment: "Development" # Environment: prod, staging, dev
    app.maborak.com/family: "Backend" # Technology family: backend, frontend, database
    app.maborak.com/runtime: "EKS" # Runtime: eks, gke, aks, docker-desktop
    app.maborak.com/service-runtime: "Python" # Service runtime: nodejs, python, go
    app.maborak.com/team: "Platform" # Team name
    app.maborak.com/tier: "T1" # Application tier: T1, T2, T3
    app.maborak.com/type: "Business" # Application type: business, infrastructure, platform

    # ArgoCD instance label
    argocd.argoproj.io/instance: "amazon-watcher-stack" # ArgoCD application instance name

    # Platform-specific labels
    platform.maborak.com/namespace: "amazon-watcher-stack" # Target namespace
    # platform.maborak.com/network-policies-version: ""
    # platform.maborak.com/istio-telemetry-api-flag: ""

  # Legacy tags (deprecated - use labels instead, but kept for backward compatibility)
  tags:
    environment: "Development" # Maps to app.maborak.com/environment
    team: "Platform" # Maps to app.maborak.com/team
    project: "amazon-watcher-stack" # Maps to app.maborak.com/project
